{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf33dc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tabulate import tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "750e6905",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------CONFIG--------------------\n",
    "source_folder = r\"C:\\Users\\Ravi Pal\\my_projects\\project_p767\\Taxi_management_db\\data\\manual_operation_data\"\n",
    "destination_folder = r\"C:\\Users\\Ravi Pal\\my_projects\\project_p767\\Taxi_management_db\\data\\manul_files\"\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "# print(os.path.exists(source_folder))  # Should be True\n",
    "# print(os.path.exists(destination_folder))  # Should be True\n",
    "# print(os.listdir(source_folder))      # Should list files   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "61be58f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed in memory: TRG PICKUP 08-12-2025.xlsx | Rows: 96\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pd.set_option('future.no_silent_downcasting', True) \n",
    "# 1. Load Data\n",
    "try:\n",
    "    # Step A: Read the dirty Excel file\n",
    "    # header=None ensures we grab every row as raw data\n",
    "    raw_df = pd.read_excel(file_path, header=None)\n",
    "\n",
    "    # Step B: \"Convert\" to CSV in memory (The trick)\n",
    "    csv_buffer = io.StringIO()\n",
    "    raw_df.to_csv(csv_buffer, index=False, header=False)\n",
    "    \n",
    "    # Rewind the buffer to the beginning so we can read it\n",
    "    csv_buffer.seek(0)\n",
    "\n",
    "    # Step C: Read it back as a clean CSV\n",
    "    df = pd.read_csv(csv_buffer, header=None)\n",
    "\n",
    "    # --- NOW YOU CAN CLEAN 'df' HERE ---\n",
    "    # Example cleaning:\n",
    "    df = df.replace(r'^\\s*$', pd.NA, regex=True) # Replace spaces\n",
    "    df.dropna(how='all', inplace=True)           # Drop empty rows\n",
    "    \n",
    "    print(f\"Processed in memory: {file} | Rows: {len(df)}\")\n",
    "    \n",
    "    # You can now perform your logic on 'df' without saving any CSVs\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "target_str = \"EMPLOYEE ADDRESS\"\n",
    "df[\"reporting_location\"] = df[4].astype(str).apply(lambda x : x if target_str in x else \"\")\n",
    "# Extract everything inside the first pair of double quotes\n",
    "df[\"reporting_location\"] = df[\"reporting_location\"].str.extract(r'\"([^\"]*)\"')\n",
    "df[\"reporting_location\"] = df[\"reporting_location\"].ffill()\n",
    "# Extract the date string (e.g., \"01-12-2025\")\n",
    "# This assumes you have the column 'source_file' from the previous step\n",
    "# 1. First, create the 'source_file' column\n",
    "df['source_file'] = file  \n",
    "\n",
    "# 2. NOW you can extract data from it\n",
    "# Extract date: looks for pattern \"DD-MM-YYYY\"\n",
    "df['date'] = df['source_file'].str.extract(r'(\\d{2}-\\d{2}-\\d{4})')\n",
    "df['reporting_date'] = pd.to_datetime(df['date'], dayfirst=True)\n",
    "\n",
    "\n",
    "df = df.dropna(how=\"all\")\n",
    "df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "df = df.dropna(how=\"all\")\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "   # 4. Rename Columns\n",
    "header_mapping = {\n",
    "    0: 'Trip_id', 1: 'trg_type', 2: 'Employee_ID', 3: 'Employee_Name',\n",
    "    4: 'Address', 5: 'Driver_Mobile', 6: 'cab_4_digit', 7: 'pickup_time',\n",
    "    8: 'shift_time', 9: 'mis_remarks', 10: 'gender', 11: 'Trip_Sheet_ID_Raw'\n",
    "}\n",
    "df = df.rename(columns=header_mapping)\n",
    "\n",
    "target_str2 = \"EMP ID\"\n",
    "if \"Employee_ID\" in df.columns:\n",
    "    df = df[~df[\"Employee_ID\"].astype(str).str.contains(target_str2, na=False, regex=False)]\n",
    "\n",
    "df[\"Trip_id\"] = df[\"Trip_id\"].ffill()\n",
    "df[\"Trip_No\"] = \"ROUTE NO : \" + df[\"Trip_id\"].astype(str)\n",
    "\n",
    "# 1. Force convert 'date' to datetime first (Handle errors gracefully)\n",
    "df['date'] = pd.to_datetime(df['date'], dayfirst=True, errors='coerce')\n",
    "\n",
    "# 2. Now you can safely use .dt accessor to get a clean string\n",
    "df['DATE_STR'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# 3. Clean up SHIFT_TIME (ensure it's a string)\n",
    "df['shift_time'] = df['shift_time'].astype(str).str.strip()\n",
    "\n",
    "# 4. Combine them\n",
    "df['temp_combined'] = df['DATE_STR'] + ' ' + df['shift_time']\n",
    "\n",
    "# 5. Create the final datetime object\n",
    "df['REPORTING_TIME'] = pd.to_datetime(df['temp_combined'], errors='coerce')\n",
    "\n",
    "df['date'] = df['date'].dt.date\n",
    "\n",
    "# Numeric Conversion\n",
    "cols_to_numeric = ['Employee_ID','cab_4_digit']\n",
    "df[cols_to_numeric] = df[cols_to_numeric].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "\n",
    "\n",
    "   # --- UPPERCASE & CLEANUP ---\n",
    "df.columns = df.columns.astype(str).str.strip().str.upper()\n",
    "str_cols = df.select_dtypes(include=['object']).columns\n",
    "df[str_cols] = df[str_cols].apply(lambda x: x.astype(str).str.strip().str.upper())\n",
    "\n",
    "desired_order = [\n",
    "    'DATE',\n",
    "    'TRIP_ID', \n",
    "    'TRIP_NO',\n",
    "    'TRG_TYPE', \n",
    "    'EMPLOYEE_ID',\n",
    "    'GENDER', \n",
    "    'EMPLOYEE_NAME', \n",
    "    'ADDRESS',  \n",
    "    'CAB_4_DIGIT',  \n",
    "    'SHIFT_TIME',\n",
    "    'REPORTING_TIME', \n",
    "    'REPORTING_LOCATION',  \n",
    "    'MIS_REMARKS'   \n",
    "]\n",
    "\n",
    "df = df.reindex(columns=desired_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec2c6cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # print(f\"Scanning folder: {source_folder}\")\n",
    "    files_found = 0\n",
    "    for root, dirs, files in os.walk(source_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(('.xls', '.xlsx')):\n",
    "                files_found += 1\n",
    "                file_path = os.path.join(root, file)\n",
    "                # clean_data(file_path, destination_folder)\n",
    "    \n",
    "    if files_found == 0:\n",
    "        print(\"No Excel files found to process.\")\n",
    "    else:\n",
    "        print(\"Processing complete.\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e543012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Data: (95, 13)\n",
      "|    | DATE       |   TRIP_ID | TRIP_NO      | TRG_TYPE     |   EMPLOYEE_ID |   GENDER | EMPLOYEE_NAME          | ADDRESS                                                                                                     |   CAB_4_DIGIT | SHIFT_TIME   | REPORTING_TIME      | REPORTING_LOCATION   |   MIS_REMARKS |\n",
      "|---:|:-----------|----------:|:-------------|:-------------|--------------:|---------:|:-----------------------|:------------------------------------------------------------------------------------------------------------|--------------:|:-------------|:--------------------|:---------------------|--------------:|\n",
      "|  1 | 2025-12-08 |         5 | ROUTE NO : 5 | BATCH NO.326 |      80054295 |      nan | SAPNA                  | KHUSHBOO HIMANI RESIDENCE RAJPUR KHURD VILLAGE, MAIDAN GARHI, NEW DELHI, DELHI 195494                       |          7798 | 06:30:00     | 2025-12-08 06:30:00 | AITA SEC 75 GURGAON  |           nan |\n",
      "|  2 | 2025-12-08 |         5 | ROUTE NO : 5 | BATCH NO.326 |      80054707 |      nan | MANISHA                | PLOT NUMBER 14 AGGARWAL FARM SATBARI NEAR MADE EASY SCHOOL,MADE EASY SCHOOL,DELHI,SOUTH DELHI,110074,DL,IND |          7798 | 06:30:00     | 2025-12-08 06:30:00 | AITA SEC 75 GURGAON  |           nan |\n",
      "|  3 | 2025-12-08 |         6 | ROUTE NO : 6 | BATCH-323    |      80060047 |      nan | LAISHRAM ANURADHA DEVI | KISHANGARH, VASANT KUNJ, 143/9, VSS DEPARTMENT STORE, 110070, DELHI SOUTH.                                  |          7885 | 06:30:00     | 2025-12-08 06:30:00 | AITA SEC 75 GURGAON  |           nan |\n",
      "|  4 | 2025-12-08 |         6 | ROUTE NO : 6 | BATCH NO.326 |      80051677 |      nan | SELTUN SONIA           | KISHANGARH SOP MANIPUR NEAR RAKESH GENERAL STORE, SHANI BAZAR 110070                                        |          7885 | 06:30:00     | 2025-12-08 06:30:00 | AITA SEC 75 GURGAON  |           nan |\n",
      "|  5 | 2025-12-08 |         6 | ROUTE NO : 6 | BATCH-323    |      80059123 |      nan | ANSHUL SHARMA          | HOUSE NOÂ 402, BUILDING NO 365, MAHIPALPUR, LANDMARK LABOUR CHOCK, SOUTHWEST DELHI, 110037.                  |          7885 | 06:30:00     | 2025-12-08 06:30:00 | AITA SEC 75 GURGAON  |           nan |\n"
     ]
    }
   ],
   "source": [
    "# df_d = df[df['reporting_location'].notna() & (df['reporting_location'] != \"\")]\n",
    "# print(df_d.head().to_markdown())\n",
    "print(f\"Shape of Data: {df.shape}\")\n",
    "print(df.head().to_markdown())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "52cf7dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 95 entries, 1 to 95\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   DATE                95 non-null     object        \n",
      " 1   TRIP_ID             95 non-null     object        \n",
      " 2   TRIP_NO             95 non-null     object        \n",
      " 3   TRG_TYPE            95 non-null     object        \n",
      " 4   EMPLOYEE_ID         95 non-null     int64         \n",
      " 5   GENDER              95 non-null     object        \n",
      " 6   EMPLOYEE_NAME       95 non-null     object        \n",
      " 7   ADDRESS             95 non-null     object        \n",
      " 8   CAB_4_DIGIT         95 non-null     int64         \n",
      " 9   SHIFT_TIME          95 non-null     object        \n",
      " 10  REPORTING_TIME      95 non-null     datetime64[ns]\n",
      " 11  REPORTING_LOCATION  95 non-null     object        \n",
      " 12  MIS_REMARKS         95 non-null     object        \n",
      "dtypes: datetime64[ns](1), int64(2), object(10)\n",
      "memory usage: 10.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
