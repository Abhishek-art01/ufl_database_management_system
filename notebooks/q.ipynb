{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b42f6678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning folder: C:\\Users\\Ravi Pal\\my_projects\\project_p767\\Taxi_management_db\\data\\manual_operation_data...\n",
      "\n",
      "Processed: TRG PICKUP 01-12-2025.xlsx | Rows: 81\n",
      "Processed: TRG PICKUP 02-12-2025.xlsx | Rows: 46\n",
      "Processed: TRG PICKUP 03-12-2025.xlsx | Rows: 81\n",
      "Processed: TRG PICKUP 04-12-2025.xlsx | Rows: 106\n",
      "Processed: TRG PICKUP 05-12-2025.xlsx | Rows: 60\n",
      "Processed: TRG PICKUP 06-12-2025.xlsx | Rows: 34\n",
      "Processed: TRG PICKUP 08-12-2025.xlsx | Rows: 96\n",
      "----------------------------------------\n",
      "Processing complete.\n",
      "Total files merged: 7\n",
      "Total combined rows: 504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ravi Pal\\AppData\\Local\\Temp\\ipykernel_25836\\2024664258.py:52: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(r'^\\s*$', np.nan, regex=True)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tabulate import tabulate\n",
    "\n",
    "# ------------------- CONFIG --------------------\n",
    "source_folder = r\"C:\\Users\\Ravi Pal\\my_projects\\project_p767\\Taxi_management_db\\data\\manual_operation_data\"\n",
    "destination_folder = r\"C:\\Users\\Ravi Pal\\my_projects\\project_p767\\Taxi_management_db\\data\\manul_files\"\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "all_data_frames = []  # List to hold all the pieces\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    files_found = 0\n",
    "    print(f\"Scanning folder: {source_folder}...\\n\")\n",
    "\n",
    "    for root, dirs, files in os.walk(source_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(('.xls', '.xlsx')):\n",
    "                files_found += 1\n",
    "                file_path = os.path.join(root, file)\n",
    "\n",
    "                try:\n",
    "                    # --- Step A: Read the dirty Excel file ---\n",
    "                    # header=None ensures we grab every row as raw data\n",
    "                    raw_df = pd.read_excel(file_path, header=None)\n",
    "\n",
    "                    # CHECK: If file is effectively empty, skip it to avoid errors\n",
    "                    if raw_df.empty:\n",
    "                        print(f\"Skipping empty file: {file}\")\n",
    "                        continue\n",
    "\n",
    "                    # --- Step B: \"Convert\" to CSV in memory ---\n",
    "                    csv_buffer = io.StringIO()\n",
    "                    raw_df.to_csv(csv_buffer, index=False, header=False)\n",
    "                    csv_buffer.seek(0) # Rewind buffer\n",
    "\n",
    "                    # --- Step C: Read it back as a clean CSV ---\n",
    "                    try:\n",
    "                        df = pd.read_csv(csv_buffer, header=None)\n",
    "                    except pd.errors.EmptyDataError:\n",
    "                        print(f\"Skipping file (no columns found): {file}\")\n",
    "                        continue\n",
    "\n",
    "                    # --- Step D: YOUR CLEANING LOGIC ---\n",
    "                    target_str = \"EMPLOYEE ADDRESS\"\n",
    "\n",
    "                    # 1. Clean whitespace and drop empty rows\n",
    "                    df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "                    df = df.dropna(how='all')\n",
    "                    df = df.reset_index(drop=True)\n",
    "\n",
    "                    # 2. Logic for 'reporting_location' (Safety check included)\n",
    "                    # We check if column 4 exists to prevent crashes on smaller files\n",
    "                    if 4 in df.columns:\n",
    "                        df[\"reporting_location\"] = df[4].astype(str).apply(\n",
    "                            lambda x: x if target_str in x else \"\"\n",
    "                        )\n",
    "                    else:\n",
    "                        df[\"reporting_location\"] = \"\"\n",
    "\n",
    "                    # 3. Add source filename (Very useful for debugging later)\n",
    "                    df['source_file'] = file\n",
    "\n",
    "                    # --- Step E: Collect the result ---\n",
    "                    all_data_frames.append(df)\n",
    "                    print(f\"Processed: {file} | Rows: {len(df)}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "    # --- Step F: Combine everything ---\n",
    "    if all_data_frames:\n",
    "        master_df = pd.concat(all_data_frames, ignore_index=True)\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Processing complete.\")\n",
    "        print(f\"Total files merged: {files_found}\")\n",
    "        print(f\"Total combined rows: {len(master_df)}\")\n",
    "        \n",
    "        # Optional: Print first few rows to verify\n",
    "        # print(tabulate(master_df.head(), headers='keys', tablefmt='psql'))\n",
    "    else:\n",
    "        print(\"No valid data collected from any files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
